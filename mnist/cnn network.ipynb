{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "data = pd.read_csv('train.csv')\n",
    "data_na = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_data = data.drop('label',axis=1)\n",
    "data_na = data_na/255.0\n",
    "y_data = data['label']\n",
    "X_data = X_data/255.0\n",
    "y_data = y_data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data,y_data,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 10 * X_train.shape[0]\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(predictions, labels):\n",
    "  \"\"\"Return the error rate based on dense predictions and sparse labels.\"\"\"\n",
    "  return 100.0 - (\n",
    "      100.0 *\n",
    "      numpy.sum(numpy.argmax(predictions, 1) == labels) /\n",
    "      predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.int64, (None,))\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    #fully connected 1024 to 256\n",
    "    fc2 = tf.add(tf.matmul(fc1,weights['wd2']),biases['bd2'])\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2,dropout)\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc2, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.truncated_normal([5, 5, 1, 32],stddev=0.1)),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.truncated_normal([5, 5, 32, 64],stddev=0.1)),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.truncated_normal([7*7*64, 1024],stddev=0.1)),\n",
    "    # fully connected, 1024 inputs, 256 outputs\n",
    "    'wd2': tf.Variable(tf.truncated_normal([1024,256],stddev=0.1)),\n",
    "    # 256 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.truncated_normal([256, n_classes],stddev=0.1))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.truncated_normal([32],stddev=0.1)),\n",
    "    'bc2': tf.Variable(tf.truncated_normal([64],stddev=0.1)),\n",
    "    'bd1': tf.Variable(tf.truncated_normal([1024],stddev=0.1)),\n",
    "    'bd2': tf.Variable(tf.truncated_normal([256],stddev=0.1)),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_classes],stddev=0.1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy\n",
    "import sys\n",
    "import random\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter :,0.00, Minibatch Loss= 4.461624, Training Accuracy= 0.20312\n",
      "Iter :100,0.38, Minibatch Loss= 0.136753, Training Accuracy= 0.95312\n",
      "Iter :200,0.76, Minibatch Loss= 0.091208, Training Accuracy= 0.97656\n",
      "Iter :300,1.14, Minibatch Loss= 0.020163, Training Accuracy= 0.99219\n",
      "Iter :400,1.52, Minibatch Loss= 0.024872, Training Accuracy= 0.99219\n",
      "Iter :500,1.90, Minibatch Loss= 0.026697, Training Accuracy= 0.99219\n",
      "Iter :600,2.29, Minibatch Loss= 0.012894, Training Accuracy= 1.00000\n",
      "Iter :700,2.67, Minibatch Loss= 0.029908, Training Accuracy= 0.98438\n",
      "Iter :800,3.05, Minibatch Loss= 0.012798, Training Accuracy= 0.99219\n",
      "Iter :900,3.43, Minibatch Loss= 0.003755, Training Accuracy= 1.00000\n",
      "Iter :1000,3.81, Minibatch Loss= 0.031905, Training Accuracy= 0.99219\n",
      "Iter :1100,4.19, Minibatch Loss= 0.006126, Training Accuracy= 1.00000\n",
      "Iter :1200,4.57, Minibatch Loss= 0.000903, Training Accuracy= 1.00000\n",
      "Iter :1300,4.95, Minibatch Loss= 0.003760, Training Accuracy= 1.00000\n",
      "Iter :1400,5.33, Minibatch Loss= 0.020454, Training Accuracy= 0.99219\n",
      "Iter :1500,5.71, Minibatch Loss= 0.010130, Training Accuracy= 0.99219\n",
      "Iter :1600,6.10, Minibatch Loss= 0.004214, Training Accuracy= 1.00000\n",
      "Iter :1700,6.48, Minibatch Loss= 0.000851, Training Accuracy= 1.00000\n",
      "Iter :1800,6.86, Minibatch Loss= 0.001214, Training Accuracy= 1.00000\n",
      "Iter :1900,7.24, Minibatch Loss= 0.000407, Training Accuracy= 1.00000\n",
      "Iter :2000,7.62, Minibatch Loss= 0.000830, Training Accuracy= 1.00000\n",
      "Iter :2100,8.00, Minibatch Loss= 0.000618, Training Accuracy= 1.00000\n",
      "Iter :2200,8.38, Minibatch Loss= 0.000975, Training Accuracy= 1.00000\n",
      "Iter :2300,8.76, Minibatch Loss= 0.002340, Training Accuracy= 1.00000\n",
      "Iter :2400,9.14, Minibatch Loss= 0.000718, Training Accuracy= 1.00000\n",
      "Iter :2500,9.52, Minibatch Loss= 0.003622, Training Accuracy= 1.00000\n",
      "Iter :2600,9.90, Minibatch Loss= 0.000924, Training Accuracy= 1.00000\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngEQQ+ACQiP8PmbDtxAYNEqMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c19485690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test accuracy is:', 0.99060059)\n"
     ]
    }
   ],
   "source": [
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "regularizations = (tf.nn.l2_loss(weights['wd1'])+tf.nn.l2_loss(weights['wd2'])+\n",
    "                  tf.nn.l2_loss(weights['out'])+tf.nn.l2_loss(biases['bd1'])+\n",
    "                  tf.nn.l2_loss(biases['bd2'])+tf.nn.l2_loss(biases['out']))\n",
    "#cost += 5e-4 * regularizations\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    offset = 0\n",
    "    lossed = []\n",
    "    accs = []\n",
    "    preds = []\n",
    "    index = range(X_train.shape[0])\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        if offset > (X_train.shape[0]-batch_size):\n",
    "            random.shuffle(index)\n",
    "        offset = offset%(X_train.shape[0]-batch_size)\n",
    "        batch_x = X_train.iloc[index[offset:(offset + batch_size)], :]\n",
    "        batch_y = y_train.iloc[index[offset:(offset + batch_size)]]\n",
    "        offset = offset + batch_size\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              keep_prob: 1.})\n",
    "            lossed.append(loss)\n",
    "            print(\"Iter :%.d,%.2f\"%(step,1.0*step*batch_size/X_train.shape[0]) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "    plt.plot(numpy.squeeze(lossed))\n",
    "    plt.xlabel('iteration perhundred')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    for i in range(X_test.shape[0]/batch_size-1):\n",
    "        acc = sess.run(accuracy, feed_dict={x: X_test[i*batch_size:(i+1)*batch_size],\n",
    "                                            y: y_test[i*batch_size:(i+1)*batch_size],\n",
    "                                            keep_prob: 1.})\n",
    "        accs.append(acc)\n",
    "    print(\"test accuracy is:\",numpy.mean(accs))\n",
    "    for i in range(data_na.shape[0]/140):\n",
    "        pred_test = sess.run(pred, feed_dict={x:data_na[i*140:(i+1)*140],\n",
    "                                         y:y_train[i*140:(i+1)*140],\n",
    "                                         keep_prob: 1.})\n",
    "        preds.append(numpy.argmax(pred_test,axis=1))\n",
    "    preds = numpy.reshape(preds,[-1,1])\n",
    "    preds = numpy.squeeze(preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
